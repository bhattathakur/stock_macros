{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b759e1-c099-4d54-9865-df666a5f0f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import talib\n",
    "import os\n",
    "sys.path.append('/home/thakur/test')\n",
    "import html_template as html\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89240e30-d19a-4cc7-9353-945a5fa6b718",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_list=['AMD','TSLA']\n",
    "print(f\"\\nDowloading {st_list} from yahoo finance...\\n\")\n",
    "data = yf.download(\n",
    "    tickers=st_list,\n",
    "    period='4wk',\n",
    "    threads=True,\n",
    "    group_by='ticker',\n",
    "    interval='5m',\n",
    "    rounding=True)\n",
    "    \n",
    "    #save to csv files\n",
    "\n",
    "for i in st_list:\n",
    "    df=data[i]\n",
    "    df.to_csv(i+\".csv\")\n",
    "    print(f\"{i}.csv created !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da57509-7091-4e0c-a501-ace988f08e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 min\n",
    "df=pd.read_csv('AMD.csv')\n",
    "# df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "# df[\"Date\"]=df[\"Date\"].apply(lambda x:x.strftime(\"%Y/%m/%d\"))\n",
    "\n",
    "df.tail()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc8f643-9e5f-429e-911d-17a5df5ab670",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/python3\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "info=\\\n",
    "'''\n",
    "This program gives the mean and std of some of the paramters user want to have.\n",
    "'''\n",
    "\n",
    "print(info)\n",
    "\n",
    "ticker,days=input(\"Enter ticker and days: \").split()\n",
    "days=int(days)\n",
    "#ticker='tsla' #ticker\n",
    "ticker=ticker.upper()\n",
    "#days=20\n",
    "\n",
    "file=ticker+\".csv\"\n",
    "\n",
    "print(f\"\\nTICKER : {ticker}\")\n",
    "print(f\"DAYS   : {days}\")\n",
    "\n",
    "#possible dirs snp,mega, large, medium, small, micro,nano\n",
    "root='/home/thakur/test/'\n",
    "dirs=['snp500','mega','large','medium','small','micro','nano']\n",
    "\n",
    "\n",
    "for i,d in enumerate(dirs):\n",
    "    print(f\"\\n{i+1}/{len(dirs)}) Looking into {d} ...\")\n",
    "    file_path=root+d+'/'+file\n",
    "    if os.path.exists(file_path):\n",
    "        print(f'{ticker} exists at {d}\\n')\n",
    "        df=pd.read_csv(file_path)\n",
    "        df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "        df[\"Date\"]=df[\"Date\"].apply(lambda x:x.strftime(\"%Y/%m/%d\"))\n",
    "        df[\"Volume\"]=df[\"Volume\"]/10**6\n",
    "        df.set_index(\"Date\", inplace=True)\n",
    "        #df.index = df.index.strftime('%m/%d/%Y')\n",
    "\n",
    "        #df['Date'] = df['Date'].strftime('%Y/%m/%d')\n",
    "        df=df.tail(days)[::-1]\n",
    "        print(100*\"=\")\n",
    "        print(f\"\\nLatest data of {ticker}:\\n {df.head()}\")\n",
    "        df['close-open']=df['Close']-df['Open']\n",
    "        df['high-open']=df['High']-df['Open']\n",
    "        df['high-low']=df['High']-df['Low']\n",
    "        df['open-low']=df['Open']-df['Low']\n",
    "        print(100*\"=\")\n",
    "        print(f\"\\nLatest data of {ticker}:\\n {df.head()}\")\n",
    "        print(100*\"=\")\n",
    "        desired_list=['close-open','high-open','high-low','open-low','Volume']\n",
    "        df_discribe=df[desired_list].describe().loc[['mean','std','min','max','25%','50%','75%','count']]\n",
    "        #df_discribe=df_discribe.describe().loc[['count','max']]\n",
    "        print(f\"DESCRIPTION:\\n{df_discribe.round(2)}\")\n",
    "        print(100*\"=\")\n",
    "        break\n",
    "    print(f\"\\n{ticker} doesn't exist!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2f09cf-be30-4734-ba75-fe6d3543ccf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #dir_name='/home/thakur/test/snp500/'\n",
    "# dir_name='/home/thakur/test/large/'\n",
    "# tickers=os.listdir(dir_name)#[:10]\n",
    "\n",
    "# tick=tickers[:1]\n",
    "df=pd.read_csv('/home/thakur/test/mega/AMZN.csv')\n",
    "df=df.tail(20)[::-1]\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8fc39f-cba0-4141-8d0b-98249177c519",
   "metadata": {},
   "outputs": [],
   "source": [
    "#close-open\n",
    "df['close-open']=df['Close']-df['Open']\n",
    "df['high-open']=df['High']-df['Open']\n",
    "df['high-low']=df['High']-df['Low']\n",
    "df['open-low']=df['Open']-df['Low']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261ffad2-7278-438e-8c15-2ea055f0f504",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_list=['close-open','high-open','high-low','open-low']\n",
    "avg=df[desired_list].mean()\n",
    "#print(f\"{high_open_avg:0.2f}\")\n",
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c975029-f4d7-4ceb-b4c3-2be6196c0e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "std=df[desired_list].std()\n",
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdecc903-7ae1-4dfc-891e-dee6dae59c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_discribe=df[desired_list].describe()\n",
    "df_discribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7e1ff4-ac6e-4b05-9584-f3b77a3d95f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/python3\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "info=\\\n",
    "'''\n",
    "This program gives the mean and std of some of the paramters user want to have.\n",
    "'''\n",
    "\n",
    "print(info)\n",
    "\n",
    "ticker,days=input(\"Enter ticker and days: \").split()\n",
    "days=int(days)\n",
    "#ticker='tsla' #ticker\n",
    "ticker=ticker.upper()\n",
    "#days=20\n",
    "\n",
    "file=ticker+\".csv\"\n",
    "\n",
    "print(f\"\\nTICKER : {ticker}\")\n",
    "print(f\"DAYS   : {days}\")\n",
    "\n",
    "#possible dirs snp,mega, large, medium, small, micro,nano\n",
    "root='/home/thakur/test/'\n",
    "dirs=['snp500','mega','large','medium','small','micro','nano']\n",
    "\n",
    "\n",
    "for i,d in enumerate(dirs):\n",
    "    print(f\"\\n{i+1}/{len(dirs)}) Looking into {d} ...\")\n",
    "    file_path=root+d+'/'+file\n",
    "    if os.path.exists(file_path):\n",
    "        print(f'{ticker} exists at {d}\\n')\n",
    "        df=pd.read_csv(file_path)\n",
    "        df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "        df[\"Date\"]=df[\"Date\"].apply(lambda x:x.strftime(\"%Y/%m/%d\"))\n",
    "        df[\"Volume\"]=df[\"Volume\"]/10**6\n",
    "        df.set_index(\"Date\", inplace=True)\n",
    "        #df.index = df.index.strftime('%m/%d/%Y')\n",
    "\n",
    "        #df['Date'] = df['Date'].strftime('%Y/%m/%d')\n",
    "        df=df.tail(days)[::-1]\n",
    "        print(100*\"=\")\n",
    "        print(f\"\\nLatest data of {ticker}:\\n {df.head()}\")\n",
    "        df['close-open']=df['Close']-df['Open']\n",
    "        df['high-open']=df['High']-df['Open']\n",
    "        df['high-low']=df['High']-df['Low']\n",
    "        df['open-low']=df['Open']-df['Low']\n",
    "        print(100*\"=\")\n",
    "        print(f\"\\nLatest data of {ticker}:\\n {df.head()}\")\n",
    "        print(100*\"=\")\n",
    "        desired_list=['close-open','high-open','high-low','open-low','Volume']\n",
    "        df_discribe=df[desired_list].describe().loc[['mean','std','min','max','25%','50%','75%','count']]\n",
    "        #df_discribe=df_discribe.describe().loc[['count','max']]\n",
    "        print(f\"DESCRIPTION:\\n{df_discribe.round(2)}\")\n",
    "        print(100*\"=\")\n",
    "        break\n",
    "    print(f\"\\n{ticker} doesn't exist!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c43fdd8-a141-43b6-8afe-68e3e03dc576",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "df['close-open']\n",
    "plt.plot(df['close-open'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a37644-630b-4bbe-87fb-efa1922b28ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_list=['AAPL','AMZN','GOOG']\n",
    "print(f\"\\nDowloading {st_list} from yahoo finance...\\n\")\n",
    "data = yf.download(\n",
    "    tickers=st_list,\n",
    "    period='52wk',\n",
    "    threads=True,\n",
    "    group_by='ticker',\n",
    "    interval='1D',\n",
    "    rounding=True)\n",
    "    \n",
    "    #save to csv files\n",
    "\n",
    "for i in st_list:\n",
    "    df=data[i]\n",
    "    df.to_csv(i+\".csv\")\n",
    "    print(f\"{i}.csv created !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f83fb7-8f25-4eec-bfac-0c424b47ca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('AAPL.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c516eb-df9c-4da1-ac2c-9281661e9ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ema8=talib.EMA(df.Close,timeperiod=8)\n",
    "ema8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c46dd8-9272-4103-bb46-46b794576128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "df=yf.download(\"AAPL\",interval='1d',start='2022-01-01',end='2022-10-06')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d813b8fa-ce17-4e21-911d-7ddd8ac76f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day=pd.read_csv(file)\n",
    "df_day[\"Date\"] = pd.to_datetime(df_day[\"Date\"])\n",
    "df_day.set_index(\"Date\", inplace=True)\n",
    "df_day.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1862d481-259c-4794-9517-c54c265d80a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "days=3\n",
    "df_daily=df_day['Adj Close'].tail(days)\n",
    "df_monthly=df_day['Adj Close'].resample(rule='BM').last().tail(days)\n",
    "df_weekly=df_day['Adj Close'].resample(rule='W').last().tail(days+1)\n",
    "#df_monthly=df_day['Adj Close'].resample('BM',how=lambda x:x[-1])\n",
    "df_monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3223691b-bf64-4f61-8671-ee32702d62f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ce5ee9-2cf6-4817-bcb4-73fe2cbb6a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_increasing=df_monthly.is_monotonic_increasing\n",
    "month_decreasing=df_monthly.is_monotonic_decreasing\n",
    "week_increasing=df_weekly.is_monotonic_increasing\n",
    "week_decreasing=df_weekly.is_monotonic_decreasing\n",
    "day_increasing=df_daily.is_monotonic_increasing\n",
    "day_decreasing=df_daily.is_monotonic_decreasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dfd5eb-6805-4485-881c-dbd70cf07699",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_increasing,month_decreasing,week_increasing,week_decreasing,day_increasing,day_decreasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0ed7ec-7417-4125-98a6-1a0ee0c37b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_status_df(file,days=3):\n",
    "    \"\"\"\n",
    "    Checks whether the df is increasing for days, weeks and months and retrns the list.\n",
    "    \"\"\"\n",
    "    #read the file\n",
    "    df_day=pd.read_csv(file)\n",
    "    df_day[\"Date\"] = pd.to_datetime(df_day[\"Date\"])\n",
    "    df_day.set_index(\"Date\", inplace=True)\n",
    "    #tick\n",
    "    tick=file.split('.')[0].split('/')[-1]\n",
    "    \n",
    "    #get the dataframe\n",
    "    df_daily=df_day['Adj Close'].tail(days)\n",
    "    df_monthly=df_day['Adj Close'].resample(rule='BM').last().tail(days)\n",
    "    df_weekly=df_day['Adj Close'].resample(rule='W').last().tail(days+1)\n",
    "    \n",
    "    #checking the status\n",
    "    month_increasing=df_monthly.is_monotonic_increasing\n",
    "    month_decreasing=df_monthly.is_monotonic_decreasing\n",
    "    week_increasing=df_weekly.is_monotonic_increasing\n",
    "    week_decreasing=df_weekly.is_monotonic_decreasing\n",
    "    day_increasing=df_daily.is_monotonic_increasing\n",
    "    day_decreasing=df_daily.is_monotonic_decreasing\n",
    "    \n",
    "    chk_day=\"up\" if day_increasing else \"down\" if day_decreasing else \"none\"\n",
    "    chk_week=\"up\" if week_increasing else \"down\" if week_decreasing else \"none\"\n",
    "    \n",
    "    chk_month=\"up\" if month_increasing else \"down\" if month_decreasing else \"none\"\n",
    "    #print([tick,chk_day,chk_week,chk_month])\n",
    "    return [tick,chk_day,chk_week,chk_month]\n",
    "\n",
    "csb_folder=\"/home/thakur/test/TXT/{}.csv\"\n",
    "\n",
    "def get_multiple_df(df,save_name):\n",
    "    d_up=(df['DAILY']=='up');d_down=(df['DAILY']=='down')\n",
    "    w_up=(df['WEEKLY']=='up');w_down=(df['WEEKLY']=='down')\n",
    "    m_up=(df['MONTHLY']=='up');m_down=(df['MONTHLY']=='down')\n",
    "    #day up, week up, month up\n",
    "    condition1=((d_up) & (w_up) & (m_up))\n",
    "    df_1=df[condition1]\n",
    "    #print(f\"df_duwupmup:\\n{df_1}\")\n",
    "    temp=save_name+\"_dwm_up\"\n",
    "    print(f\"save_name: {temp}\")\n",
    "    #html.save_txt_html(df_1,temp,temp) #df,save,title,rows=100\n",
    "    df_1.to_csv(csb_folder.format(temp))\n",
    "    \n",
    "    #day up, week up\n",
    "    condition2=((d_up) & (w_up))\n",
    "    df_2=df[condition2]\n",
    "    print(f\"df_dup_wup:\\n{df_2}\")\n",
    "    \n",
    "    #week up, month up\n",
    "    condition3=((m_up) & (w_up))\n",
    "    df_3=df[condition3]\n",
    "    print(f\"df_wup_mup:\\n{df_3}\")\n",
    "    \n",
    "    #month up\n",
    "    condition4=((d_up)&(m_up))\n",
    "    df_4=df[condition4]\n",
    "    print(f\"df_dup_mup:\\n{df_4}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac434e07-108f-4760-a4ee-ce4f5c8d4c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#file_dirs=[\"/home/thakur/test/mega/\",\"/home/thakur/test/large/\",\"/home/thakur/test/medium/\",\"/home/thakur/test/\"]\n",
    "root=\"/home/thakur/test/\"\n",
    "sources=[\"mega\"]#,\"large\",\"medium\",\"large\",\"small\",\"micro\",\"nano\",\"snp500\"]\n",
    "file_dirs=[root+i+\"/\" for i in sources]\n",
    "columns=['TICKER','DAILY','WEEKLY','MONTHLY']\n",
    "for c,d in enumerate(file_dirs):\n",
    "    print(f\"{c+1}/{len(sources)}) Working for {sources[c]} ...\")\n",
    "    save_file=sources[c]\n",
    "    print(f\"save_file: {save_file}\\n\")\n",
    "    temp=[]\n",
    "    tickers=os.listdir(d)\n",
    "    for tick in tickers:\n",
    "        file=d+tick\n",
    "        temp.append(get_status_df(file))\n",
    "    #print(f\"temp: {temp}\\n\")\n",
    "    test=pd.DataFrame(temp,columns=columns)\n",
    "    get_multiple_df(test,save_file)\n",
    "    #test.to_csv(save_file+\".csv\",index=False)\n",
    "    print(f\"test:\\n {test}\\n\")\n",
    "    #test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df2aa1f-6706-4620-8e06-c6d6fcb02de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_file=\"/home/thakur/test/mega/\"\n",
    "tickers=os.listdir(mega_file)\n",
    "for tick in tickers:\n",
    "    file=mega_file+tick\n",
    "    get_status_df(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71659428-cd01-4df5-aa50-9d8c607c70ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_up=(df['DAILY']=='up');dd_down=(df['DAILY']=='down')\n",
    "dw_up=(df['WEEKLY']=='up');dw_down=(df['WEEKLY']=='down')\n",
    "dm_up=(df['MONTHLY']=='up');dm_down=(df['MONTHLY']=='down')\n",
    "save_file=\"temp_dwm_\"+sources[1]+\".csv\"\n",
    "save_file\n",
    "df=pd.read_csv(save_file)\n",
    "df=df[(dm_up) & (dd_up) & (dw_up)]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5187de4f-99e9-4f0e-bb40-bd44e24f6134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# today=datetime.today().strftime(\"%m/%d/%Y\")\n",
    "# end_of_business_month=pd.bdate_range(start='1/1/2021',end=today,freq='BM')\n",
    "# end_of_business_week=pd.bdate_range(start='1/1/2021',end=today,freq='W')\n",
    "                        \n",
    "# # df_monthly=df_day.asfreq(freq='1w')\n",
    "# # #df_monthly=df_day['Adj Close'].resample('BM',how=lambda x:x[-1])\n",
    "# # df_monthly\n",
    "# end_of_business_week\n",
    "# test='/home/thakur/test/mega/JPM.csv'\n",
    "\n",
    "# test=test.split('.')[0].split('/')[-1]\n",
    "#test=test[-1:]\n",
    "# test\n",
    "\n",
    "txt_folder=\"/home/thakur/test/TXT/{}.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390c8c32-47c6-4210-9279-946ef8f3abf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmt_str='/home/thakur/test/TXT/{}.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9081a405-0e7b-484d-9a81-e0b4cbae6716",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_week=df_day['Adj Close'].resample('w').last()\n",
    "# df_week\n",
    "# today=datetime.today().strftime(\"%m/%d/%Y\")\n",
    "# today\n",
    "#df_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bda8288-f005-4c5e-9a65-c2198a9f2e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs=['mega','large','medium','small','micro','nano','snp500']\n",
    "for k,j in enumerate(dirs[:]): \n",
    "    dir_name='/home/thakur/test/{}/'.format(dirs[k])\n",
    "    tickers=os.listdir(dir_name)\n",
    "    oops=[]\n",
    "    for c,i in enumerate(tickers):\n",
    "        file=dir_name+i\n",
    "        #print(f\"File:({c+1}/{len(tickers)})--> {file}\")\n",
    "        df=pd.read_csv(file)\n",
    "        tick=i.split('.')[0]\n",
    "        #print(f\"Current data for {tick}:\\n{df.tail(5)}\")\n",
    "        yesterday=df.tail(2).head(1)\n",
    "        #print(f\"Second last data for {tick}:\\n{yesterday}\")\n",
    "\n",
    "        today=df.tail(1)\n",
    "        #print(f\"Last data for {tick}:\\n{today}\")\n",
    "\n",
    "        low_yesterday=yesterday['Low'].values[0]\n",
    "        open_today=today['Open'].values[0];close_today=today['Close'].values[0]\n",
    "        # print(f\"Yesterday's low for {tick}:\\n{low_yesterday}\")\n",
    "        # print(f\"Today's open for {tick}:\\n{open_today}\")\n",
    "        # print(f\"Today's close for {tick}:\\n{close_today}\")\n",
    "        oops_status=True if (open_today<low_yesterday and close_today>low_yesterday) else False\n",
    "        #print(f\"oops_status for {tick}: {oops_status}\\n\")\n",
    "        if oops_status:oops.append(tick)\n",
    "\n",
    "    print(f\"Tickers following OOPS condition for {j}:\\n{oops}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d4815b-84bb-446f-a386-75d6ceff7f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "oops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafff7a4-6c9b-410d-8574-bbe2ae31eaef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5461902c-df83-464a-a4eb-b5ddc8982b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "oops=[]\n",
    "for c,i in enumerate(tickers):\n",
    "    file=dir_name+i\n",
    "    #print(f\"File:({c+1}/{len(tickers)})--> {file}\")\n",
    "    df=pd.read_csv(file)\n",
    "    tick=i.split('.')[0]\n",
    "    #print(f\"Current data for {tick}:\\n{df.tail(5)}\")\n",
    "    yesterday=df.tail(2).head(1)\n",
    "    #print(f\"Second last data for {tick}:\\n{yesterday}\")\n",
    "    \n",
    "    today=df.tail(1)\n",
    "    #print(f\"Last data for {tick}:\\n{today}\")\n",
    "    \n",
    "    low_yesterday=yesterday['Low'].values[0]\n",
    "    open_today=today['Open'].values[0];close_today=today['Close'].values[0]\n",
    "    # print(f\"Yesterday's low for {tick}:\\n{low_yesterday}\")\n",
    "    # print(f\"Today's open for {tick}:\\n{open_today}\")\n",
    "    # print(f\"Today's close for {tick}:\\n{close_today}\")\n",
    "    oops_status=True if (open_today<low_yesterday and close_today>low_yesterday) else False\n",
    "    #print(f\"oops_status for {tick}: {oops_status}\\n\")\n",
    "    if oops_status:oops.append(tick)\n",
    "\n",
    "print(f\"Tickers following OOPS condition:\\n{oops}\")\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
