{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mplfinance as mpf\n",
    "import os\n",
    "import pandas_ta as ta\n",
    "\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run snp500 listupdate to get the list of latest snp500 tickers: http://localhost:8888/lab/tree/snp500listupdate.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#st_df=pd.read_csv(\"/home/thakur/stock_information/sectoretf.csv\") #more sectors\n",
    "st_df=pd.read_csv(\"/home/thakur/stock_information/sectors.csv\")  #11 sectors\n",
    "st_list=st_df[\"TICKER\"].to_list()\n",
    "# st_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data=yf.download(\"XLE\",period='20d')\n",
    "# sector_list=st_df['SECTOR'].to_list()\n",
    "# sector_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download all tickers\n",
    "save=\"/home/thakur/test/sector/\"\n",
    "print(f\"\\nDowloading {st_list} data from yahoo finance...\\n\")\n",
    "data = yf.download(\n",
    "tickers=st_list,\n",
    "period='52wk',\n",
    "threads=True,\n",
    "group_by='ticker',\n",
    "rounding=True)\n",
    "\n",
    "#save to csv filesb\n",
    "print(f\"Saving to {save}...\\n\")\n",
    "for i in st_list:\n",
    "    df=data[i]\n",
    "    df.to_csv(save+i+\".csv\")\n",
    "    print(f\"{i}.csv created !\")\n",
    "    #print(f\"{i} head:\\n\")\n",
    "    #print(df.head(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_index(df):\n",
    "    \"\"\"Begins the index of df from 1\"\"\"\n",
    "    df.index=np.arange(1,len(df.index)+1)\n",
    "    return df\n",
    "\n",
    "#create yfinance portfolio sample\n",
    "def yahoo_portfolio(df,save_name):\n",
    "    \"\"\"\n",
    "    returns the yfinance compatable portfolio template for given df name of save file\n",
    "    \"\"\"\n",
    "    cols=['Symbol','Current Price','Date', 'Time', 'Change', 'Open', 'High', 'Low', 'Volume', 'Trade Date',\n",
    "          'Purchase Price','Quantity','Commission','High Limit','Low Limit','Comment']\n",
    "\n",
    "    sym=list(df.TICK)\n",
    "    dic_val=[sym]+14*[None]            #14 None\n",
    "    my_dict=dict(zip(cols,dic_val))    #dictionary\n",
    "    my_df=pd.DataFrame.from_dict(my_dict)\n",
    "    my_df.to_csv(save_name+\".csv\")\n",
    "    print(f\"Created the yahoo template: {save_name}.csv from data frame !\")\n",
    "    \n",
    "def plot_with_mpl(tick,root,day=60,sty='charles',typ='candle'):\n",
    "    \"returns the candle stick of a stock tick for the given root file.\"\n",
    "\n",
    "    df=pd.read_csv(root+tick+\".csv\").tail(day)\n",
    "    df.Volume=df.Volume/10**5              #100k volume\n",
    "    df.Date=pd.to_datetime(df.Date)\n",
    "    df.set_index('Date',inplace=True)\n",
    "    fig,axes=mpf.plot(df,type=typ,mav=(5,10),volume=True,tight_layout=False,figratio=(72,36),figscale=1,\n",
    "                    returnfig=True,style=sty)\n",
    "    axes[0].legend([\"5-SMA\",\"10-SMA\"],loc='upper center')\n",
    "    #axes[0].legend(loc='upper left')\n",
    "    axes[0].set_title(tick)\n",
    "    mpf.show()\n",
    "\n",
    "    \n",
    "def print_info(c,sector,industry,name,symbol,cp):\n",
    "    print(f\"\\n\\n\\nCOUNT   : {c+1}\")\n",
    "    print(f\"SECTOR  : {sector}\\nINDUSTRY: {industry}\\nNAME    : {name}\\nSYMBOL  : {symbol}\\nPRICE   : $ {cp}\\n\\n\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the files\n",
    "ticker_list=[]           #store ticker\n",
    "current_price=[]         #current price\n",
    "\n",
    "HH=[]                    #higher high\n",
    "HL=[]                    #higher low\n",
    "LH=[]                    #lower high\n",
    "LL=[]                    #lower low\n",
    "HC=[]                    #higher close\n",
    "rsi=[]                   #rsi list\n",
    "sma_5=[]                 #sma_5 list\n",
    "sma_21=[]                 #sma_21 list\n",
    "sma_50=[]                 #sma_50 list\n",
    "sma_200=[]                 #sma_200 list\n",
    "vol=[]                    #vol today\n",
    "avgvol=[]                 #avg volume\n",
    "pt_change=[]             #% change\n",
    "atr=[]                   #atr\n",
    "sec_list=[]             #sector\n",
    "ind_list=[]             #industry\n",
    "d=3                     #days for hh etc.\n",
    "j=1                     #counter\n",
    "fil=\"sector\"\n",
    "csv_source=\"/home/thakur/test/sector/\"\n",
    "for f in st_list:#[:5]:    #read these files\n",
    "    print(f\"{j}/{len(st_list)} {fil} : {f}\\n\")\n",
    "    j+=1\n",
    "\n",
    "    #print(\"source dir\\t\",csv_source)\n",
    "    df=pd.read_csv(csv_source+f+\".csv\")\n",
    "    df.fillna(0,inplace=True)\n",
    "\n",
    "    #print the tail\n",
    "    #print(f\"Tail of {i}\\n {df.tail(1)}\")\n",
    "\n",
    "    #ticker\n",
    "    ticker_list.append(f)\n",
    "\n",
    "    #current price \n",
    "    cp=round(df.tail(1)['Close'].values[0],2)\n",
    "    #print(f\"Current Price: {cp}\")\n",
    "    current_price.append(cp)\n",
    "\n",
    "    #higher high\n",
    "    hh=df.tail(d)['High'].is_monotonic_increasing\n",
    "    #print(f\"HH: {hh}\\n\")\n",
    "    HH.append(hh)\n",
    "\n",
    "    ##higher low\n",
    "    hl=df.tail(d)['Low'].is_monotonic_increasing\n",
    "    #print(f\"HL: {hl}\\n\")\n",
    "    HL.append(hl)\n",
    "\n",
    "    #lower high\n",
    "    lh=df.tail(d)['High'].is_monotonic_decreasing\n",
    "    #print(f\"LH: {lh}\\n\")\n",
    "    LH.append(lh)\n",
    "\n",
    "    ##lower low\n",
    "    ll=df.tail(d)['Low'].is_monotonic_decreasing\n",
    "    #print(f\"LL: {ll}\\n\")\n",
    "    LL.append(ll)\n",
    "\n",
    "    #higher close\n",
    "    hc=df.tail(d)['Close'].is_monotonic_increasing\n",
    "    #print(f\"HC: {hc}\\n\")\n",
    "    HC.append(hc)\n",
    "\n",
    "    #rsi\n",
    "    rs=df.ta.rsi()[-1:].round(2).values[0]\n",
    "    #print(f\"rs\\t{rs}\")\n",
    "    rsi.append(rs)\n",
    "\n",
    "    #sma5\n",
    "    sma5=round(df.tail(5)['Close'].mean(),2)\n",
    "    #print(f\"sma5: {sma5}\")\n",
    "    sma_5.append(sma5)\n",
    "\n",
    "    #sma21\n",
    "    sma21=round(df.tail(21)['Close'].mean(),2)\n",
    "    #print(f\"sma21: {sma21}\")\n",
    "    sma_21.append(sma21)\n",
    "\n",
    "    #sma50\n",
    "    sma50=round(df.tail(50)['Close'].mean(),2)\n",
    "    #print(f\"sma50: {sma50}\")\n",
    "    sma_50.append(sma50)\n",
    "\n",
    "    #sma200\n",
    "    sma200=round(df.tail(200)['Close'].mean(),2)\n",
    "    #print(f\"sma200: {sma200}\")\n",
    "    sma_200.append(sma200)\n",
    "\n",
    "    #last volume\n",
    "    v=(df.tail(1)['Volume'].values[0])/10**6\n",
    "    v=round(v,2)\n",
    "    vol.append(v)\n",
    "    #print(f\"today's volume {v} thousands\")\n",
    "\n",
    "    #last volume\n",
    "    av=(df.tail(d)['Volume'].mean())/10**5\n",
    "    av=round(av,2)\n",
    "    avgvol.append(av)\n",
    "    #print(f\"today's volume {av} thousands\")\n",
    "\n",
    "    #pct change\n",
    "    pct=round((df.tail(2)['Close'].pct_change().values[1])*100,2)\n",
    "    #print(f\"%Change:\\n {pct}\")\n",
    "    #pct=2\n",
    "    pt_change.append(pct)\n",
    "    #pct_change.append(pct)\n",
    "    #print(f\"%Change: {pct}\")\n",
    "\n",
    "    #atr value\n",
    "    df_20=df.tail(24) #for 10 day avg atr\n",
    "    #at=round(ta.atr(df_20['High'],df_20['Low'],df_20['Close']).values[-1],2)\n",
    "    at=round(ta.atr(df_20['High'],df_20['Low'],df_20['Close']).mean(),2)\n",
    "    #print(f\"atr: {at}\")\n",
    "    atr.append(at)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#create the data-frame\n",
    "temp_df=pd.DataFrame({\"TICKER\":ticker_list,\n",
    "                          \"CP\":current_price,\n",
    "                          \"HH\":HH,\n",
    "                          \"HL\":HL,\n",
    "                          \"LH\":LH,\n",
    "                          \"LL\":LL,\n",
    "                          \"HC\":HC,\n",
    "                          \"RSI\":rsi,\n",
    "                          \"SMA5\":sma_5,\n",
    "                          \"SMA21\":sma_21,\n",
    "                          \"SMA50\":sma_50,\n",
    "                          \"SMA200\":sma_200,\n",
    "                          \"VOL\":vol,\n",
    "                          \"AVGVOL\":avgvol,\n",
    "                          \"%CHG\":pt_change,\n",
    "                          \"AVG10ATR\":atr,\n",
    "                         })\n",
    "temp_df.to_csv('/home/thakur/test/combined/all_sectors.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df[\"SECTOR\"]=st_df[\"SECTOR\"];temp_df[\"SUBINDUSTRY\"]=\"N/A\";temp_df[\"NAME\"]=\"N/A\"\n",
    "#temp_df=temp_df[(temp_df['HH']==True)&(temp_df['HL']==True)]\n",
    "temp_df=temp_df.sort_values(by=['RSI'],ascending=False)\n",
    "temp_df=change_index(temp_df)\n",
    "#temp_df.set_index('TICKER',inplace=True)\n",
    "temp_df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df=temp_df[['TICKER','RSI','VOL','%CHG','AVG10ATR']]\n",
    "#plot_df.loc[:,'%CHG']=plot_df.loc[:,'%CHG'].multiply(10)\n",
    "#plot_df.reset_index(inplace=True)\n",
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=plot_df.columns.to_list()\n",
    "x=columns[0];y=columns[1:]\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "today=datetime.now().strftime(\"%m/%d/%Y\")\n",
    "#sns.set_style(\"ticks\",{'axes.grid' : True})\n",
    "\n",
    "# sns.set_style(\"whitegrid\", {\n",
    "#     \"ytick.major.size\": 0.1,\n",
    "#     \"ytick.minor.size\": 0.05,\n",
    "#     'grid.linestyle': '--'\n",
    "#  })\n",
    "\n",
    "# Apply the default theme\n",
    "sns.set_theme()\n",
    "#sns.bar(plot_df)\n",
    "# sns.barplot(data=plot_df,x='TICKER',y='RSI')\n",
    "# sns.barplot(data=plot_df,x='TICKER',y='VOL')\n",
    "f, axs = plt.subplots(2, 2, figsize=(15, 10), gridspec_kw=dict(width_ratios=[4, 4]))\n",
    "cols=axs.flat\n",
    "for i,j in enumerate(y):\n",
    "    g=sns.barplot(data=plot_df,x=x,y=y[i],ax=cols[i])\n",
    "    #g.semilogy()\n",
    "f.suptitle(f\"SECTOR {today}\")   \n",
    "f.tight_layout()\n",
    "f.savefig(\"sector.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all snp data\n",
    "pd.set_option('display.max_columns', None);pd.set_option('display.max_rows', None)\n",
    "# select_cols_snp=['TICKER', 'CP', 'EMA8','RSI',\n",
    "#        'SMA5', 'SMA10', 'SMA21', 'SMA50', 'SMA200', 'VOL', 'AVGVOL5', 'CHG%',\n",
    "#        'ATR14']\n",
    "select_cols_w=['SYMBOL', 'NAME', 'SECTOR', 'SUBINDUSTRY']\n",
    "\n",
    "df_snp=pd.read_csv(\"/home/thakur/test/combined/all_snp.csv\")#[select_cols_snp]\n",
    "df_snp_w_sector=pd.read_csv(\"/home/thakur/stock_information/snp500finalwvol.csv\")[select_cols_w]\n",
    "df_snp_w_sector.rename(columns={\"SYMBOL\":\"TICKER\"},inplace=True)\n",
    "df_snp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snp_w_sector.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snp_w_sector.shape,df_snp.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['NAME','SECTOR','SUBINDUSTRY']:df_snp[i]=df_snp_w_sector[i]\n",
    " \n",
    "#df_snp['NAME']=df_snp_w_sector['NAME'];df_snp['SECTOR']=df_snp_w_sector['SECTOR'];df_snp['SUBINDUSTRY']=df_snp_w_sector['SUBINDUSTRY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the type of the companay mega, large, medium, small, micro, nano\n",
    "import os\n",
    "root=\"/home/thakur/test/\"\n",
    "group=['mega','large','medium','small','micro','nano']\n",
    "dirs=[root+i+\"/\" for i in group]\n",
    "#check_list=['JPM','MOS','HAS','HBIO']\n",
    "check_list=list(df_snp.TICKER)\n",
    "mega_list=os.listdir(dirs[0])\n",
    "large_list=os.listdir(dirs[1])\n",
    "medium_list=os.listdir(dirs[2])\n",
    "small_list=os.listdir(dirs[3])\n",
    "micro_list=os.listdir(dirs[4])\n",
    "nano_list=os.listdir(dirs[5])\n",
    "\n",
    "category=[]\n",
    "for i in check_list:\n",
    "    file=i+\".csv\"\n",
    "    if file in mega_list:\n",
    "        #print(f\"{i}: mega\")\n",
    "        #category.append([i,\"mega\"])\n",
    "        category.append(\"mega\")\n",
    "    elif file in large_list:\n",
    "        #print(f\"{i}: large\")\n",
    "        #category.append([i,\"large\"])\n",
    "        category.append(\"large\")\n",
    "    elif file in medium_list:\n",
    "        #print(f\"{i}: medium\")\n",
    "        category.append(\"medium\")\n",
    "        #category.append([i,\"medium\"])\n",
    "    elif file in small_list:\n",
    "        #print(f\"{i}: small\")\n",
    "        category.append(\"small\")\n",
    "        #category.append([i,\"small\"])\n",
    "    elif file in micro_list:\n",
    "        #print(f\"{i}: micro\")\n",
    "        category.append(\"micro\")                \n",
    "        #category.append([i,\"micro\"])\n",
    "    elif file in nano_list:\n",
    "        #print(f\"{i}: nano\")\n",
    "        category.append(\"nano\")\n",
    "        #category.append([i,\"nano\"])\n",
    "    else:\n",
    "        #print(f\"{i}: nano\")\n",
    "        category.append(\"N/A\")\n",
    "#nano_list\n",
    "\n",
    "# for i in group:\n",
    "#     dirr=root+i+\"/\"\n",
    "#     ticker_list=os.listdir(dirr)\n",
    "#     print(f'ticker list {ticker_list}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snp['CATEGORY']=category\n",
    "df_snp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snp.loc[df_snp['CATEGORY']=='N/A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the type of the companay mega, large, medium, small, micro, nano\n",
    "import os\n",
    "root=\"/home/thakur/test/\"\n",
    "group=['mega','large','medium','small','micro','nano']\n",
    "dirs=[root+i+\"/\" for i in group]\n",
    "#check_list=['JPM','MOS','HAS','HBIO']\n",
    "check_list=list(df_snp.TICKER)\n",
    "mega_list=os.listdir(dirs[0])\n",
    "large_list=os.listdir(dirs[1])\n",
    "medium_list=os.listdir(dirs[2])\n",
    "small_list=os.listdir(dirs[3])\n",
    "micro_list=os.listdir(dirs[4])\n",
    "nano_list=os.listdir(dirs[5])\n",
    "\n",
    "for i in check_list:\n",
    "    file=i+\".csv\"\n",
    "    if file in mega_list:\n",
    "        print(f\"{i}: mega\")\n",
    "    elif file in large_list:\n",
    "        print(f\"{i}: large\")\n",
    "    elif file in medium_list:\n",
    "        print(f\"{i}: medium\")\n",
    "    elif file in small_list:\n",
    "        print(f\"{i}: small\")\n",
    "    elif file in micro_list:\n",
    "        print(f\"{i}: micro\")\n",
    "    elif file in nano_list:\n",
    "        print(f\"{i}: nano\")\n",
    "#nano_list\n",
    "\n",
    "# for i in group:\n",
    "#     dirr=root+i+\"/\"\n",
    "#     ticker_list=os.listdir(dirr)\n",
    "#     print(f'ticker list {ticker_list}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the type of the companay mega, large, medium, small, micro, nano\n",
    "import os\n",
    "root=\"/home/thakur/test/\"\n",
    "group=['mega','large','medium','small','micro','nano']\n",
    "check_tick='PLTR'\n",
    "\n",
    "# for c,i in enumerate(group):\n",
    "#     path=path+group[c]\n",
    "#     file=check_tick+'.csv'\n",
    "#     if os.path.exists(file):\n",
    "#         print(f\"File: {file} exista at {path}\")\n",
    "#         break\n",
    "#     #if check_tick+\".csv' \n",
    "def get_categorty(file):\n",
    "    # for c,i in enumerate(group):\n",
    "    #     path=path+group[c]\n",
    "    #     print(f\"path: {path}\")\n",
    "    #     file=check_tick+'.csv'\n",
    "    path=root+group[0]\n",
    "    if os.path.exists(file):\n",
    "        print(f\"File: {file} exista at {path}\")\n",
    "        path=\"/home/thakur/test/\"\n",
    "        print(f\"path: {path}\")\n",
    "        return group[0]\n",
    "    \n",
    "    path=root+group[1]\n",
    "    if os.path.exists(file):\n",
    "        print(f\"File: {file} exista at {path}\")\n",
    "        path=\"/home/thakur/test/\"\n",
    "        print(f\"path: {path}\")\n",
    "        return group[1]\n",
    "    \n",
    "    path=root+group[2]\n",
    "    if os.path.exists(file):\n",
    "        print(f\"File: {file} exista at {path}\")\n",
    "        path=\"/home/thakur/test/\"\n",
    "        print(f\"path: {path}\")\n",
    "        return group[2]\n",
    "    \n",
    "    path=root+group[3]\n",
    "    if os.path.exists(file):\n",
    "        print(f\"File: {file} exista at {path}\")\n",
    "        path=\"/home/thakur/test/\"\n",
    "        print(f\"path: {path}\")\n",
    "        return group[3]\n",
    "    \n",
    "    path=root+group[4]\n",
    "    if os.path.exists(file):\n",
    "        print(f\"File: {file} exista at {path}\")\n",
    "        path=\"/home/thakur/test/\"\n",
    "        print(f\"path: {path}\")\n",
    "        return group[4]\n",
    "    \n",
    "    path=root+group[5]\n",
    "    if os.path.exists(file):\n",
    "        print(f\"File: {file} exista at {path}\")\n",
    "        path=\"/home/thakur/test/\"\n",
    "        print(f\"path: {path}\")\n",
    "        return group[5]\n",
    "        # elif os.path.exists(file):\n",
    "        #     print(f\"File: {file} exista at {path}\")\n",
    "        #     path=\"/home/thakur/test/\"\n",
    "        #     print(f\"path: {path}\")\n",
    "        #     return group[c]\n",
    "        # else:\n",
    "        #     continue\n",
    "\n",
    "\n",
    "# def get_categorty(check_tick,path):\n",
    "#     for c,i in enumerate(group):\n",
    "#         path=path+group[c]\n",
    "#         print(f\"path: {path}\")\n",
    "#         file=check_tick+'.csv'\n",
    "#         if os.path.exists(file):\n",
    "#             print(f\"File: {file} exista at {path}\")\n",
    "#             path=\"/home/thakur/test/\"\n",
    "#             print(f\"path: {path}\")\n",
    "#             return group[c]\n",
    "#         else:\n",
    "#             continue\n",
    "get_categorty('AMD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total=list(df_snp['TICKER'])\n",
    "for k in total:\n",
    "    get_categorty(k,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsi_order=list(temp_df.SECTOR)\n",
    "rsi_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_snp.loc['Health Care']\n",
    "choice='Energy'\n",
    "kind='CP'\n",
    "temp_df=df_snp[df_snp['SECTOR']==choice]\n",
    "h_test=((temp_df['HH']==True)&(temp_df['HL']==True) & (temp_df['HC']==True))\n",
    "temp_df=temp_df[h_test]\n",
    "temp_df=temp_df.sort_values(by=[kind],ascending=True)\n",
    "temp_df=change_index(temp_df)\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_source='/home/thakur/test/snp500/'\n",
    "for c,i in enumerate(temp_df['TICKER'].tolist()):\n",
    "    sector=temp_df.loc[c+1,\"SECTOR\"];industry=temp_df.loc[c+1,\"SUBINDUSTRY\"];cp=temp_df.loc[c+1,\"CP\"];name=temp_df.loc[c+1,\"NAME\"]\n",
    "\n",
    "    print_info(c,sector,industry,name,i,cp)\n",
    "    plot_with_mpl(i,csv_source,20,'charles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_mpl(tick,root,day=60,sty='yahoo',typ='candle'):\n",
    "    \"returns the candle stick of a stock tick for the given root file.\"\n",
    "\n",
    "    df=pd.read_csv(root+tick+\".csv\").tail(day)\n",
    "    df.Volume=df.Volume/10**5              #100k volume\n",
    "    df.Date=pd.to_datetime(df.Date)\n",
    "    df.set_index('Date',inplace=True)\n",
    "    fig,axes=mpf.plot(df,type=typ,mav=(5,10),volume=True,tight_layout=False,figratio=(72,36),figscale=1,\n",
    "                    returnfig=True,style=sty)\n",
    "    axes[0].legend([\"5-SMA\",\"10-SMA\"],loc='upper center')\n",
    "    #axes[0].legend(loc='upper left')\n",
    "    axes[0].set_title(tick)\n",
    "    mpf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.query('HH & HL & HC').sort_values(by='CP')\n",
    "temp_df.plot(x=temp_df.TICKER,y=temp_df.RSI,kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "root='/home/thakur/test/snp500/'\n",
    "day=50\n",
    "cols=math.ceil(temp_df.shape[0]/3)\n",
    "\n",
    "\n",
    "fig,axs=plt.figure(3,cols)\n",
    "\n",
    "for tick in temp_df['TICKER'].to_list():\n",
    "    df=pd.read_csv(root+tick+\".csv\").tail(day)\n",
    "    df.Volume=df.Volume/10**5                             #100k volume\n",
    "    df.Date=pd.to_datetime(df.Date)\n",
    "    df.set_index('Date',inplace=True)\n",
    "    df['Adj Close'].plot()\n",
    "    print(f\"{df.head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "math.ceil(temp_df.shape[0]/3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#return a df for given sector components\n",
    "def sector_df(sector):\n",
    "    return df_snp.loc(\"SECTOR\"==sector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy=sector_df(\"Energy\")\n",
    "energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector=list(df_snp.SECTOR.unique());subindustry=list(df_snp.SUBINDUSTRY.unique())\n",
    "sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tick='XLF'\n",
    "df=pd.read_csv(f'/home/thakur/test/sector/{tick}.csv').tail(20)\n",
    "df['Date']=df['Date'].apply(lambda x:x.split()[0])\n",
    "df['Volume']=df['Volume'].divide(10**6).round(2)\n",
    "#df['Date']=pd.to_datetime(df['Date'])\n",
    "#df=df.set_index('Date')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #plot_df.plot(kind='bar')\n",
    "# # Import seaborn\n",
    "# import seaborn as sns\n",
    "\n",
    "# # Apply the default theme\n",
    "# sns.set_theme()\n",
    "# #sns.bar(plot_df)\n",
    "# # sns.barplot(data=plot_df,x='TICKER',y='RSI')\n",
    "# # sns.barplot(data=plot_df,x='TICKER',y='VOL')\n",
    "# f, axs = plt.subplots(2, 2, figsize=(12, 8), gridspec_kw=dict(width_ratios=[4, 4]))\n",
    "# sns.barplot(data=plot_df,x='TICKER',y='RSI',ax=axs[0,0])\n",
    "# sns.barplot(data=plot_df,x='TICKER',y='VOL',ax=axs[0,1])\n",
    "# sns.barplot(data=plot_df,x='TICKER',y='%CHG',ax=axs[1,0])\n",
    "# sns.barplot(data=plot_df,x='TICKER',y='AVG10ATR',ax=axs[1,1])\n",
    "# f.tight_layout()\n",
    "# #f.savefig(\"test.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,axs=plt.subplots(1,2,figsize=(30,10))\n",
    "sns.barplot(data=df,x='Date',y='Volume',ax=axs[0])\n",
    "sns.lineplot(data=df,x='Date',y='Adj Close',ax=axs[1])\n",
    "# axs[0].tick_params(axis='x', rotation=30)\n",
    "# axs[1].tick_params(axis='x', rotation=30)\n",
    "for i,j in enumerate(axs.flat):\n",
    "    axs[i].tick_params(axis='x', rotation=30)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df=pd.DataFrame()\n",
    "summary_df['RSI']=temp_df.sort_values(by=['RSI'],ascending=False).index\n",
    "summary_df['VOL']=temp_df.sort_values(by=['VOL'],ascending=False).index\n",
    "summary_df['CP']=temp_df.sort_values(by=['CP'],ascending=False).index\n",
    "summary_df['+CHG']=temp_df.sort_values(by=['%CHG'],ascending=False).index\n",
    "summary_df['ATR']=temp_df.sort_values(by=['AVG10ATR'],ascending=False).index\n",
    "\n",
    "\n",
    "# def insert_columns(values_by,given_df=temp_df):\n",
    "#     temp=given_df.sort_values(by=[values_by])\n",
    "#     summary_df[values_by]=given_df['TICKER']\n",
    "#     return summary_df\n",
    "\n",
    "# test=insert_columns(\"CP\");\n",
    "# #insert_columns(\"RSI\")\n",
    "# test\n",
    "# temp_df.set_index('TICKER')\n",
    "summary_df=change_index(summary_df)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c,i in enumerate(temp_df['TICKER'].tolist()):\n",
    "    sector=temp_df.loc[c+1,\"SECTOR\"];industry=temp_df.loc[c+1,\"SUBINDUSTRY\"];cp=temp_df.loc[c+1,\"CP\"];name=temp_df.loc[c+1,\"NAME\"]\n",
    "\n",
    "    print_info(c,sector,industry,name,i,cp)\n",
    "    plot_with_mpl(i,csv_source,50,'default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp_df[\"SECTOR\"]=st_df[\"SECTOR\"];temp_df[\"SUBINDUSTRY\"]=\"N/A\";temp_df[\"NAME\"]=\"N/A\"\n",
    "#temp_df=temp_df[(temp_df['HH']==True)&(temp_df['HL']==True)]\n",
    "temp_df_rsi=temp_df.sort_values(by=['RSI'],ascending=False)\n",
    "temp_df_rsi=change_index(temp_df_rsi)\n",
    "temp_df_rsi.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RSI\\n\")\n",
    "for c,i in enumerate(temp_df_rsi['TICKER'].tolist()):\n",
    "    sector=temp_df_rsi.loc[c+1,\"SECTOR\"];industry=temp_df_rsi.loc[c+1,\"SUBINDUSTRY\"];cp=temp_df_rsi.loc[c+1,\"CP\"];name=temp_df_rsi.loc[c+1,\"NAME\"]\n",
    "\n",
    "    print_info(c,sector,industry,name,i,cp)\n",
    "    plot_with_mpl(i,csv_source,50,'default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp_df[\"SECTOR\"]=st_df[\"SECTOR\"];temp_df[\"SUBINDUSTRY\"]=\"N/A\";temp_df[\"NAME\"]=\"N/A\"\n",
    "#temp_df=temp_df[(temp_df['HH']==True)&(temp_df['HL']==True)]\n",
    "temp_df=temp_df.sort_values(by=['%CHG'],ascending=False)\n",
    "temp_df=change_index(temp_df)\n",
    "temp_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c,i in enumerate(temp_df['TICKER'].tolist()):\n",
    "    sector=temp_df.loc[c+1,\"SECTOR\"];industry=temp_df.loc[c+1,\"SUBINDUSTRY\"];cp=temp_df.loc[c+1,\"CP\"];name=temp_df.loc[c+1,\"NAME\"]\n",
    "\n",
    "    print_info(c,sector,industry,name,i,cp)\n",
    "    plot_with_mpl(i,csv_source,50,'default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test file\n",
    "dff=pd.read_csv(save+\"XLF.csv\",parse_dates=['Date'])\n",
    "dff.set_index('Date',inplace=True)\n",
    "dff.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test file\n",
    "dff1=pd.read_csv(save+\"XLF.csv\",parse_dates=['Date'],index_col='Date')\n",
    "#dff.set_index('Date',inplace=True)\n",
    "dff1.tail()\n",
    "#dff1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dff['Date']=pd.to_datetime(dff.Date)\n",
    "# dff.set_index('Date')\n",
    "\n",
    "#dff['Date'].dt.day_name()\n",
    "#dff.index.min(),df.index.max()\n",
    "#dff['2022-01-01':]\n",
    "#df_close=dff1['Close'].resample('W').agg(['min','max'])\n",
    "#df_agg=dff1.resample('W').agg(['min','max'])\n",
    "df_agg=dff1.resample('BM').agg({'Volume':'mean'})\n",
    "df_agg['Volume']=round(df_agg['Volume']/10**6,2)\n",
    "df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "dff2=dff1.resample('W').last()#.agg()\n",
    "#df_agg['Volume']=round(df_agg['Volume']/10**6,2)\n",
    "#df_agg\n",
    "dff2[-4:]\n",
    "plt.plot(dff2.index,dff2.Close,label='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib qt\n",
    "#matplotlib inline\n",
    "plt.figure(figsize=(16,8))\n",
    "dff3=dff1.resample('BM').last()#.agg()\n",
    "#df_agg['Volume']=round(df_agg['Volume']/10**6,2)\n",
    "#df_agg\n",
    "dff3[-4:]\n",
    "plt.plot(dff3.index,dff3.Close,'r--',label='m')\n",
    "plt.plot(dff2.index,dff2.Close,'b-.',label='w')\n",
    "plt.plot(dff1.index,dff1.Close,'g',label='d')\n",
    "plt.xlim('2022-05','2022-08-30')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib qt\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "fig, axs = plt.subplots(3, 1,figsize=(6,4))\n",
    "axs[0].plot(dff1.tail(20).index,dff1.tail(20).Close,'r',label='d')\n",
    "#axs[0, 0].set_title('Axis [0, 0]')\n",
    "dff2=dff2.tail(20)\n",
    "axs[1].plot(dff2.index,dff2.Close,'b',label='w')\n",
    "axs[2].plot(dff3.index,dff3.Close,'g',label='m')\n",
    "fig.legend()\n",
    "plt.tight_layout()\n",
    "# axs[0, 1].set_title('Axis [0, 1]')\n",
    "# axs[1, 0].plot(x, -y, 'tab:green')\n",
    "# axs[1, 0].set_title('Axis [1, 0]')\n",
    "# axs[1, 1].plot(x, -y, 'tab:red')\n",
    "# axs[1, 1].set_title('Axis [1, 1]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = mpf.figure(figsize=(12,8),style='yahoo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = fig.add_subplot(3,1,1)\n",
    "ax2 = fig.add_subplot(3,1,2)\n",
    "ax3 = fig.add_subplot(3,1,3)\n",
    "mpf.plot(dff1,ax=ax1,type='candle',axtitle=\"daily\")\n",
    "mpf.plot(dff2,ax=ax2,type='candle',axtitle=\"weekly\")\n",
    "mpf.plot(dff3,ax=ax3,type='candle',axtitle=\"monthly\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apds = [mpf.make_addplot(exp12,color='lime'),\n",
    "        mpf.make_addplot(exp26,color='c'),\n",
    "        mpf.make_addplot(histogram,type='bar',width=0.7,panel=1,\n",
    "                         color='dimgray',alpha=1,secondary_y=False),\n",
    "        mpf.make_addplot(macd,panel=1,color='fuchsia',secondary_y=True),\n",
    "        mpf.make_addplot(signal,panel=1,color='b',secondary_y=True),\n",
    "       ]\n",
    "\n",
    "mpf.plot(df,type='candle',addplot=apds,figscale=1.1,figratio=(8,5),title='\\nMACD',\n",
    "         style='blueskies',volume=True,volume_panel=2,panel_ratios=(6,3,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w=dff1[dff1.index.day_name()=='Friday']\n",
    "df_w.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "df_agg.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group by week \n",
    "# df_week=dff.resample('BM',on='Date')\n",
    "# df_week.min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group by week \n",
    "# df_week=dff.resample('BM',on='Date')\n",
    "# df_week.max()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
